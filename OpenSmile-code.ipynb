{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31c6e2f2",
   "metadata": {},
   "source": [
    "### Importing all necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f661c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoX could not be found!\n",
      "\n",
      "    If you do not have SoX, proceed here:\n",
      "     - - - http://sox.sourceforge.net/ - - -\n",
      "\n",
      "    If you do (or think that you should) have SoX, double-check your\n",
      "    path variables.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "#import glob\n",
    "#import sys\n",
    "#import audiofile\n",
    "#import time\n",
    "#import pandas as pd\n",
    "import os\n",
    "import sklearn.mixture\n",
    "import opensmile\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc6b48cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xlwt import Workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1705bf",
   "metadata": {},
   "source": [
    "### Importing OpenSmile package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "799ca22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "smile = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
    "    feature_level=opensmile.FeatureLevel.Functionals,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2162f3ab",
   "metadata": {},
   "source": [
    "### Extracting all the 88 features using open smile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "452edae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPrep:\n",
    "    def __init__(self, folderPath=None):\n",
    "\n",
    "        self.folderPath = folderPath\n",
    "        self.spk_files = os.listdir(self.folderPath)\n",
    "\n",
    "        self.file_features = np.zeros((1,88))\n",
    "        Y=[0]\n",
    "        \n",
    "        for spk_file in range(len(self.spk_files)):\n",
    "            wav_path = os.path.join(self.folderPath,self.spk_files[spk_file])\n",
    "            y = smile.process_file(wav_path)\n",
    "            file_feats = np.asarray(y)\n",
    "            self.file_features = np.concatenate((self.file_features, file_feats),axis=0)\n",
    "            label = self.folderPath\n",
    "            label=label[-8]\n",
    "            if label=='f':\n",
    "                l=0\n",
    "            else:\n",
    "                l=1\n",
    "            Y.append(l)\n",
    "\n",
    "        self.file_features = self.file_features[1:,:]\n",
    "        self.labels=np.asarray(Y)\n",
    "        self.labels=self.labels.T\n",
    "        self.labels = self.labels[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e51895",
   "metadata": {},
   "source": [
    "#### Taking data from dataset which are separated as train and test data properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8456574",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have to pass correct folder paths in DataPrep to take test and train data\n",
    "\n",
    "#extracting training data\n",
    "#Train_dataF means data which is fake speech\n",
    "#Train_dataO means data which is original speech\n",
    "Train_dataF = DataPrep(r'C:\\Users\\HP\\Desktop\\Dataset\\data\\251\\Train\\fake_slt')\n",
    "Train_dataO = DataPrep(r'C:\\Users\\HP\\Desktop\\Dataset\\data\\251\\Train\\orig_slt')\n",
    "\n",
    "#extracting testing data\n",
    "#Test_dataF means data which is fake speech\n",
    "#Test_dataF means data which is original speech\n",
    "Test_dataF = DataPrep(r'C:\\Users\\HP\\Desktop\\Dataset\\data\\251\\Test\\fake_slt')\n",
    "Test_dataO = DataPrep(r'C:\\Users\\HP\\Desktop\\Dataset\\data\\251\\Test\\orig_slt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4468365b",
   "metadata": {},
   "source": [
    "#### Dividing Train Data accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6c2221b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividing train data as X_trainF, Y_trainF, X_trainO and Y_trainO\n",
    "#X_trainF means features extracted from fake speech\n",
    "#X_trainO means features extracted from original speech\n",
    "\n",
    "X_trainF=Train_dataF.file_features\n",
    "Y_trainF=Train_dataF.labels\n",
    "X_trainO=Train_dataO.file_features\n",
    "Y_trainO=Train_dataO.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2135c31e",
   "metadata": {},
   "source": [
    "#### Checking size of X_trainF, Y_trainF, X_trainO and Y_trainO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c3a86ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192, 88)\n",
      "(192, 88)\n",
      "(192,)\n",
      "(192,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_trainF))\n",
    "print(np.shape(X_trainO))\n",
    "print(np.shape(Y_trainF))\n",
    "print(np.shape(Y_trainO))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82004c1b",
   "metadata": {},
   "source": [
    "#### Dividing Test Data accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "378d8376",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividing test data as X_testF, Y_testF, X_testO and Y_testO\n",
    "#X_testF means features extracted from fake speech\n",
    "#X_testO means features extracted from original speech\n",
    "\n",
    "X_testF=Test_dataF.file_features\n",
    "Y_testF=Test_dataF.labels\n",
    "X_testO=Test_dataO.file_features\n",
    "Y_testO=Test_dataO.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b841b0",
   "metadata": {},
   "source": [
    "#### Checking size of X_testF, Y_testF, X_testO and Y_testO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1eb1d06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 88)\n",
      "(21, 88)\n",
      "(21,)\n",
      "(21,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_testF))\n",
    "print(np.shape(X_testO))\n",
    "print(np.shape(Y_testF))\n",
    "print(np.shape(Y_testO))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ed0ca0",
   "metadata": {},
   "source": [
    "#### Concatenate Fake and Non-fake speech (Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c36b073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(384, 88)\n",
      "(384,)\n"
     ]
    }
   ],
   "source": [
    "X=np.concatenate((X_trainF, X_trainO),axis=0)\n",
    "y=np.concatenate((Y_trainF, Y_trainO),axis=0)\n",
    "\n",
    "print(np.shape(X))\n",
    "print(np.shape(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991c435f",
   "metadata": {},
   "source": [
    "##### This step of train-test split done to do shuffle the data. The splitted test from the train_test_split was not used for testing. Testing was done from the testing set seperated earlier only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8724e7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72872b1d",
   "metadata": {},
   "source": [
    "### Concatanate Fake and Non-fake speech (Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "caa430e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42, 88)\n",
      "(42,)\n"
     ]
    }
   ],
   "source": [
    "X_test=np.concatenate((X_testF, X_testO),axis=0)\n",
    "y_test=np.concatenate((Y_testF, Y_testO),axis=0)\n",
    "\n",
    "print(np.shape(X_test))\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100c6d24",
   "metadata": {},
   "source": [
    "##### Remove NaN(Not a Number) from train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6fe8b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1=X_train[~np.isnan(X_train).any(axis=1)]\n",
    "nan_index=np.argwhere(np.isnan(X_train))\n",
    "\n",
    "removal_rows=np.unique(nan_index[:,0])\n",
    "y_train1=np.delete(y_train,removal_rows,axis=0)\n",
    "\n",
    "X_train=X_train1\n",
    "y_train=y_train1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91d6f20",
   "metadata": {},
   "source": [
    "##### Remove NaN(Not a Number) from test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed83c8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1=X_test[~np.isnan(X_test).any(axis=1)]\n",
    "nan_index=np.argwhere(np.isnan(X_test))\n",
    "\n",
    "removal_rows=np.unique(nan_index[:,0])\n",
    "y_test1=np.delete(y_test,removal_rows,axis=0)\n",
    "\n",
    "X_test=X_test1\n",
    "y_test=y_test1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b07672b",
   "metadata": {},
   "source": [
    "##### Checking NaN after removing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d505e0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(np.isnan((X_train))))\n",
    "print(np.sum(np.isnan((X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ff3011",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee6502bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "etc=ExtraTreesClassifier(n_estimators=50)\n",
    "etc=etc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d4762b",
   "metadata": {},
   "source": [
    "#### Finding the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3bf3ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013229288717897216"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#th=-np.sort(-etc.feature_importances_)[No. of features]\n",
    "#th is threshold\n",
    "\n",
    "th=-np.sort(-etc.feature_importances_)[5]\n",
    "th"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147b8f43",
   "metadata": {},
   "source": [
    "#### Indexes of top n features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b36821f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([32, 62, 63, 77, 78])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = [idx for idx, val in enumerate(etc.feature_importances_) if val > th]\n",
    "res=np.asarray(res)\n",
    "res.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b1654c",
   "metadata": {},
   "source": [
    "#### Picking the features according to the selected index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbed548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new=(X_train[:,res])\n",
    "X_test_new=X_test[:,res]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2cb66d",
   "metadata": {},
   "source": [
    "##### Checking shape of X_train_new and X_test_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e330a161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(383, 5)\n",
      "(42, 5)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train_new))\n",
    "print(np.shape(X_test_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193b5358",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c6e30cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 1 of 2) Processing std, total=   0.0s\n",
      "[Pipeline] ..... (step 2 of 2) Processing Random_forest, total=   0.1s\n",
      "\n",
      "Accuracy: 0.8809523809523809\n",
      "\n",
      "----------------Classification Report----------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89        21\n",
      "           1       1.00      0.76      0.86        21\n",
      "\n",
      "    accuracy                           0.88        42\n",
      "   macro avg       0.90      0.88      0.88        42\n",
      "weighted avg       0.90      0.88      0.88        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe1 = Pipeline([ ('std', StandardScaler()), ('Random_forest', RandomForestClassifier(n_estimators = 100))], verbose = True)\n",
    "pipe1.fit(X_train_new, y_train)\n",
    "prob_score_RF=pipe1.predict_proba(X_test_new)\n",
    "print(\"\\nAccuracy:\",accuracy_score(y_test, pipe1.predict(X_test_new)))\n",
    "print(\"\\n----------------Classification Report----------------\\n\\n\",classification_report(y_test,pipe1.predict(X_test_new)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f5fccc",
   "metadata": {},
   "source": [
    "#### Confusion Matrix for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6ba6a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21  0]\n",
      " [ 5 16]]\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.confusion_matrix(y_test, pipe1.predict(X_test_new)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787e36fc",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e822fde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 1 of 2) Processing std, total=   0.0s\n",
      "[Pipeline] ..... (step 2 of 2) Processing decision_tree, total=   0.0s\n",
      "\n",
      "Accuracy: 0.8333333333333334\n",
      "\n",
      "----------------Classification Report----------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86        21\n",
      "           1       1.00      0.67      0.80        21\n",
      "\n",
      "    accuracy                           0.83        42\n",
      "   macro avg       0.88      0.83      0.83        42\n",
      "weighted avg       0.88      0.83      0.83        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe2 = Pipeline([ ('std', StandardScaler()), ('decision_tree', DecisionTreeClassifier())], verbose = True)\n",
    "pipe2.fit(X_train_new, y_train)\n",
    "prob_score_DT=pipe2.predict_proba(X_test_new)\n",
    "print(\"\\nAccuracy:\",accuracy_score(y_test, pipe2.predict(X_test_new)))\n",
    "print(\"\\n----------------Classification Report----------------\\n\\n\",classification_report(y_test,pipe2.predict(X_test_new)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f6c5d2",
   "metadata": {},
   "source": [
    "#### Confusion Matrix for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ac37fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21  0]\n",
      " [ 7 14]]\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.confusion_matrix(y_test, pipe2.predict(X_test_new)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55092cd",
   "metadata": {},
   "source": [
    "### SVM (Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c70bf876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 1 of 2) Processing std, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing SVM, total=   0.0s\n",
      "\n",
      "Accuracy: 0.8571428571428571\n",
      "\n",
      "----------------Classification Report----------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88        21\n",
      "           1       1.00      0.71      0.83        21\n",
      "\n",
      "    accuracy                           0.86        42\n",
      "   macro avg       0.89      0.86      0.85        42\n",
      "weighted avg       0.89      0.86      0.85        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe4 = Pipeline([ ('std', StandardScaler()), ('SVM', SVC(kernel='linear',probability=True) )], verbose = True)\n",
    "pipe4.fit(X_train_new, y_train)\n",
    "prob_score_SVM=pipe4.predict_proba(X_test_new)\n",
    "print(\"\\nAccuracy:\",accuracy_score(y_test, pipe4.predict(X_test_new)))\n",
    "print(\"\\n----------------Classification Report----------------\\n\\n\",classification_report(y_test,pipe4.predict(X_test_new)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bc05cb",
   "metadata": {},
   "source": [
    "#### Confusion matrix for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f0ad333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21  0]\n",
      " [ 6 15]]\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.confusion_matrix(y_test, pipe4.predict(X_test_new)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3418e9",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19ca2ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 1 of 2) Processing std, total=   0.0s\n",
      "[Pipeline]  (step 2 of 2) Processing Logistic_Regression, total=   0.0s\n",
      "\n",
      "Accuracy: 0.8571428571428571\n",
      "\n",
      "----------------Classification Report----------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88        21\n",
      "           1       1.00      0.71      0.83        21\n",
      "\n",
      "    accuracy                           0.86        42\n",
      "   macro avg       0.89      0.86      0.85        42\n",
      "weighted avg       0.89      0.86      0.85        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe5 = Pipeline([ ('std', StandardScaler()), ('Logistic_Regression', LogisticRegression(random_state = 0) )], verbose = True)\n",
    "pipe5.fit(X_train_new, y_train)\n",
    "prob_score_LR=pipe5.predict_proba(X_test_new)\n",
    "print(\"\\nAccuracy:\",accuracy_score(y_test, pipe5.predict(X_test_new)))\n",
    "print(\"\\n----------------Classification Report----------------\\n\\n\",classification_report(y_test,pipe5.predict(X_test_new)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f4db2d",
   "metadata": {},
   "source": [
    "#### Confusion matrix for Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09faf51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21  0]\n",
      " [ 6 15]]\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.confusion_matrix(y_test, pipe5.predict(X_test_new)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5729284",
   "metadata": {},
   "source": [
    "### Probability Score Combination of ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2edb8e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we do probability score combination, such that different weightages are given to each ML model.\n",
    "#Where all weightages add up to 1.\n",
    "#Here a:%RF, b:%DT, c:%SVM and d:%LR\n",
    "#output will be given in excel sheet\n",
    "#wb.save(\"filename-to-be-given.xls\")\n",
    "\n",
    "wb = Workbook()\n",
    "sheet1 = wb.add_sheet('Sheet 1')\n",
    "value = 10\n",
    "count = 0\n",
    "sheet1.write(count,0,\"%RF\")\n",
    "sheet1.write(count,1,\"%DT\")\n",
    "sheet1.write(count,2,\"%SVM\")\n",
    "sheet1.write(count,3,\"%LR\")\n",
    "sheet1.write(count,4,\"Accuracy\")\n",
    "for a in range(value+1):\n",
    "    for b in range(value+1):\n",
    "        for c in range(value+1):\n",
    "            for d in range(value+1):\n",
    "                if (a+b+c+d) == value:\n",
    "                    y_pred = []\n",
    "                    for i in range(len(y_test)):\n",
    "                        score_0 = (a*prob_score_RF[i][0])+(b*prob_score_DT[i][0])+(c*prob_score_SVM[i][0])+(d*prob_score_LR[i][0])\n",
    "                        score_1 = (a*prob_score_RF[i][1])+(b*prob_score_DT[i][1])+(c*prob_score_SVM[i][1])+(d*prob_score_LR[i][1])\n",
    "                        if score_0 > score_1:\n",
    "                            y_pred.append(0)\n",
    "                        else:\n",
    "                            y_pred.append(1)\n",
    "                    sheet1.write(count+1,0,a/value)\n",
    "                    sheet1.write(count+1,1,b/value)\n",
    "                    sheet1.write(count+1,2,c/value)\n",
    "                    sheet1.write(count+1,3,d/value)\n",
    "                    sheet1.write(count+1,4,accuracy_score(y_test,y_pred))\n",
    "                    count = count + 1\n",
    "wb.save(\"LibreTTS-251.xls\")                    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
